# Case 2 – Current RAG Agent Architecture

This document describes the current RAG (Retrieval-Augmented Generation) agent implementation that candidates need to analyze and improve.

## Overview

The agent is designed to query **Base Carbone** emission factors (ADEME's carbon footprint database) and provide answers with source references. However, **the current implementation has a high hallucination rate**.

---

## Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                     RAG PIPELINE (5 STEPS)                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ STEP 1: Fast Retrieval (NO CROSS-ATTENTION)              │   │
│  │ • Method: Cosine similarity (vector search)               │   │
│  │ • Target: Top 30 candidates                               │   │
│  │ • Index: Azure AI Search                                  │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ STEP 2: Metadata / Entity Filtering                       │   │
│  │ • Filter by: category, location                           │   │
│  │ • Goal: Reduce noise before expensive models              │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ STEP 3: Re-ranking (CROSS-ATTENTION LEVEL 1)              │   │
│  │ • Method: Cross-Encoder (sentence-transformers)           │   │
│  │ • Input: 30 chunks → Output: Top 5 chunks                 │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ STEP 4: Prompt Construction                               │   │
│  │ • Template: System prompt + Context + Question            │   │
│  │ • Goal: Force LLM to use only provided context            │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ STEP 5: Answer Generation (CROSS-ATTENTION LEVEL 2)       │   │
│  │ • Method: LangChain LLM (Azure OpenAI)                    │   │
│  │ • Output: Answer + Source references                      │   │
│  └──────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## Databases (Pre-indexed)

The following databases are already stored and embedded on our side (Azure AI Search):

| Database | Description | Status |
|----------|-------------|--------|
| **Base Carbone v23.6** | ADEME carbon emission factors (~11,216 records) | ✅ Indexed |
| **Invoices** | Client invoice data for carbon footprint calculation | ✅ Indexed |

> **Note**: Candidates do NOT need to re-index these databases. They are pre-embedded and ready for retrieval.

---

## Provided Outputs

For evaluation, we provide **two outputs**:

| Output | Description |
|--------|-------------|
| **Answer A (Agent Output)** | The wrong/hallucinated answer generated by the current agent |
| **Answer B (Ground Truth)** | The correct answer that the agent should have generated |

Candidates should compare these outputs to diagnose why hallucination occurs.

---

## Key Components

### 1. Data Source
- **Base Carbone v23.6** (ADEME carbon emission factors)
- ~11,216 emission factors from Excel file
- Fields: identifier, name_fr, name_en, category, unit, location, total CO2e, etc.

### 2. Embedding
- Model: `text-embedding-3-small`
- Dimensions: 256
- Provider: Azure OpenAI

### 3. Vector Store
- **Azure AI Search**
- Index: `sola-rag-index`
- Hybrid search support (vector + keyword)

### 4. LLM
- Model: `gpt-4o-mini`
- Provider: Azure OpenAI
- Temperature: 0.7
- Framework: LangChain `AzureChatOpenAI`

### 5. Re-ranker
- Cross-Encoder (sentence-transformers)
- Imported from `rag_reranker.py`

---

## Code Flow

### Indexing Flow (`BaseCarboneExcelProcessor`)
```python
Excel File → Parse Rows → Build Content Text → Generate Embedding → Upload to Azure AI Search
```

### Query Flow (`SolaRagChat.chat()`)
```python
Question → Vector Search (k=30) → Metadata Filter → Cross-Encoder Rerank (k=5) → Prompt Build → LLM Generate → Answer + References
```

---

## Current Issues (Candidates Must Identify)

The agent has **high hallucination rate**. Candidates should analyze:

1. **Retrieval Quality** - Is the retrieval strategy effective?
2. **Chunking Strategy** - How is the content text built?
3. **Embedding Choice** - Is 256 dimensions sufficient?
4. **Prompt Design** - Does it enforce grounding?
5. **Reranking Effectiveness** - Is the cross-encoder helping?
6. **Reference Validation** - Are sources properly verified?
7. **Entity Alignment** - Are company/site names matched correctly?

---

## Files in This Case

| File | Description |
|------|-------------|
| `case2_rag.py` | Main RAG implementation |
| `case2_config.py` | Azure credentials and configuration |
| `README Case 2.md` | Case instructions (EN/CN) |
| `agent.md` | This architecture document |

---

## API Keys Provided

Candidates can use the API keys in `case2_config.py`:
- Azure OpenAI (gpt-4o-mini, text-embedding-3-small)
- Azure AI Search
- Azure Document Intelligence

---

# 案例2 – 当前 RAG 智能体架构

本文档描述了需要候选人分析和改进的当前 RAG（检索增强生成）智能体实现。

## 概述

该智能体旨在查询 **Base Carbone** 排放因子（ADEME 碳足迹数据库）并提供带有来源引用的答案。然而，**当前实现存在较高的幻觉率**。

---

## 架构

```
┌─────────────────────────────────────────────────────────────────┐
│                     RAG 流程（5个步骤）                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 步骤1：快速检索（无交叉注意力）                            │   │
│  │ • 方法：余弦相似度（向量搜索）                             │   │
│  │ • 目标：Top 30 候选                                       │   │
│  │ • 索引：Azure AI Search                                   │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 步骤2：元数据/实体过滤                                     │   │
│  │ • 过滤条件：category, location                            │   │
│  │ • 目标：在昂贵模型前减少噪音                               │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 步骤3：重排序（交叉注意力级别1）                           │   │
│  │ • 方法：Cross-Encoder (sentence-transformers)             │   │
│  │ • 输入：30个块 → 输出：Top 5个块                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 步骤4：提示词构建                                          │   │
│  │ • 模板：系统提示 + 上下文 + 问题                           │   │
│  │ • 目标：强制LLM仅使用提供的上下文                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                      │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 步骤5：答案生成（交叉注意力级别2）                         │   │
│  │ • 方法：LangChain LLM (Azure OpenAI)                      │   │
│  │ • 输出：答案 + 来源引用                                    │   │
│  └──────────────────────────────────────────────────────────┘   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 数据库（已预先索引）

以下数据库已在我们这边存储并嵌入（Azure AI Search）：

| 数据库 | 描述 | 状态 |
|--------|------|------|
| **Base Carbone v23.6** | ADEME碳排放因子（约11,216条记录） | ✅ 已索引 |
| **发票数据** | 用于碳足迹计算的客户发票数据 | ✅ 已索引 |

> **注意**：候选人无需重新索引这些数据库。它们已预先嵌入并可直接用于检索。

---

## 提供的输出

为了评估，我们提供**两个输出**：

| 输出 | 描述 |
|------|------|
| **Answer A（智能体输出）** | 当前智能体生成的错误/幻觉答案 |
| **Answer B（Ground Truth）** | 智能体应该生成的正确答案 |

候选人应比较这两个输出以诊断幻觉发生的原因。

---

## 核心组件

### 1. 数据来源
- **Base Carbone v23.6**（ADEME碳排放因子）
- 约11,216个排放因子，来自Excel文件
- 字段：identifier, name_fr, name_en, category, unit, location, total CO2e 等

### 2. 嵌入模型
- 模型：`text-embedding-3-small`
- 维度：256
- 提供商：Azure OpenAI

### 3. 向量存储
- **Azure AI Search**
- 索引：`sola-rag-index`
- 支持混合搜索（向量 + 关键词）

### 4. 大语言模型
- 模型：`gpt-4o-mini`
- 提供商：Azure OpenAI
- Temperature：0.7
- 框架：LangChain `AzureChatOpenAI`

### 5. 重排序器
- Cross-Encoder (sentence-transformers)
- 从 `rag_reranker.py` 导入

---

## 代码流程

### 索引流程 (`BaseCarboneExcelProcessor`)
```python
Excel文件 → 解析行 → 构建内容文本 → 生成嵌入向量 → 上传到 Azure AI Search
```

### 查询流程 (`SolaRagChat.chat()`)
```python
问题 → 向量搜索(k=30) → 元数据过滤 → Cross-Encoder重排序(k=5) → 构建提示词 → LLM生成 → 答案 + 引用
```

---

## 当前问题（候选人需要识别）

该智能体存在**高幻觉率**。候选人应分析：

1. **检索质量** - 检索策略是否有效？
2. **分块策略** - 内容文本如何构建？
3. **嵌入选择** - 256维度是否足够？
4. **提示词设计** - 是否强制引用？
5. **重排序效果** - Cross-encoder是否有帮助？
6. **引用验证** - 来源是否正确验证？
7. **实体对齐** - 公司/站点名称是否正确匹配？

---

## 本案例文件

| 文件 | 描述 |
|------|------|
| `case2_rag.py` | 主要RAG实现 |
| `case2_config.py` | Azure凭证和配置 |
| `README Case 2.md` | 案例说明（中英文） |
| `agent.md` | 本架构文档 |

---

## 提供的 API 密钥

候选人可以使用 `case2_config.py` 中的API密钥：
- Azure OpenAI (gpt-4o-mini, text-embedding-3-small)
- Azure AI Search
- Azure Document Intelligence
